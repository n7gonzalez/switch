{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key legend.labelcolor in file style.txt, line 43 ('legend.labelcolor: black')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_data\n",
    "from utils import tech_order, tech_colors\n",
    "from utils import get_data_sftp\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import os\n",
    "\n",
    "plt.style.use(\"style.txt\")\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_pie_chart(self, df, bins=(0, 10, 30, 60, float(\"inf\")), sizes=(100, 200, 300, 400), ax=None,\n",
    "                        title=\"Power Capacity (GW)\", legend=True):\n",
    "        \"\"\"\n",
    "        Graphs the data from the dataframe to a map pie chart.\n",
    "        The dataframe should have 3 columns, gen_load_zone, gen_type and value.\n",
    "        \"\"\"\n",
    "        _, center_points = self._load_maps()\n",
    "\n",
    "        if ax is None:\n",
    "            ax = self.draw_base_map()\n",
    "        df = df.merge(center_points, on=\"gen_load_zone\")\n",
    "\n",
    "        assert not df[\"gen_type\"].isnull().values.any()\n",
    "        colors = self._tools.get_colors()\n",
    "        lz_values = df.groupby(\"gen_load_zone\")[[\"value\"]].sum()\n",
    "        if (lz_values[\"value\"] == 0).any():\n",
    "            raise NotImplementedError(\"Can't plot when some load zones have total value of 0\")\n",
    "        lz_values[\"size\"] = self._tools.pd.cut(lz_values.value, bins=bins, labels=sizes)\n",
    "        if lz_values[\"size\"].isnull().values.any():\n",
    "            lz_values[\"size\"] = 150\n",
    "            warnings.warn(\"Not using variable pie chart size since values were out of bounds during cutting\")\n",
    "        for index, group in df.groupby(\"gen_load_zone\"):\n",
    "            x, y = group[\"geometry\"].iloc[0].x, group[\"geometry\"].iloc[0].y\n",
    "            group_sum = group.groupby(\"gen_type\")[\"value\"].sum().sort_values()\n",
    "            group_sum = group_sum[group_sum != 0].copy()\n",
    "\n",
    "            tech_color = [colors[tech] for tech in group_sum.index.values]\n",
    "            total_size = lz_values.loc[index][\"size\"]\n",
    "            ratios = (group_sum / group_sum.sum()).values\n",
    "            self._pie_plot(x, y, ratios, tech_color, total_size, ax)\n",
    "\n",
    "        if legend:\n",
    "            legend_points = []\n",
    "            for size, label in zip(sizes, self._tools.create_bin_labels(bins)):\n",
    "                legend_points.append(\n",
    "                    ax.scatter([], [], c=\"k\", alpha=0.5, s=size, label=str(label))\n",
    "                )\n",
    "            legend = ax.legend(\n",
    "                handles=legend_points,\n",
    "                title=title,\n",
    "                labelspacing=0.75,\n",
    "                bbox_to_anchor=(1, 0),\n",
    "                framealpha=0,\n",
    "                loc=\"lower left\",\n",
    "                fontsize=\"small\",\n",
    "                title_fontsize=\"small\"\n",
    "            )\n",
    "            ax.add_artist(legend)  # Required, see : https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#multiple-legends-on-the-same-axes\n",
    "\n",
    "            legend_points = []\n",
    "            for tech in df[\"gen_type\"].unique():\n",
    "                legend_points.append(\n",
    "                    ax.scatter([],[],c=colors[tech], marker=\"s\", label=tech)\n",
    "                )\n",
    "\n",
    "            legend = ax.legend(\n",
    "                handles=legend_points,\n",
    "                ncol=5,\n",
    "                loc=\"upper left\",\n",
    "                bbox_to_anchor=(0, 0),\n",
    "                # framealpha=0,\n",
    "                fontsize=\"small\",\n",
    "                title_fontsize=\"small\",\n",
    "                labelspacing=0.3\n",
    "            )\n",
    "            ax.add_artist(legend)\n",
    "\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispatch = tools.get_dataframe(\"dispatch_zonal_annual_summary.csv\").rename({\"Energy_GWh_typical_yr\": \"value\"},                                                                           axis=1)\n",
    "# dispatch = tools.transform.gen_type(dispatch)\n",
    "# dispatch = dispatch.groupby([\"gen_type\", \"gen_load_zone\"], as_index=False)[\"value\"].sum()\n",
    "# dispatch[\"value\"] *= 1e-3\n",
    "# tools.maps.graph_pie_chart(dispatch, bins=(0, 10, 100, 200, float(\"inf\")), title=\"Yearly Dispatch (TWh)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = ['s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14',\n",
    "#                  's15','s16','s17','s18','s19','s20','s21','s22','s23','s24','s25']\n",
    "scenario = ['s1','s5','s21','s25']\n",
    "short_names={'s1':'1','s2':'2','s3':'3','s4':'4','s5':'5','s6':'6','s7':'7','s8':'8',\n",
    "             's9':'9','s10':'10','s11':'11','s12':'12','s13':'13','s14':'14','s15':'15',\n",
    "             's16':'16','s17':'17','s18':'18','s19':'19','s20':'20','s21':'21','s22':'22',\n",
    "             's23':'23','s24':'24','s25':'25'}\n",
    "\n",
    "order={'1':0, '2':1,'3':2,'4':3,'5':4,'6':5,'7':6,'8':7,'9':8,'10':9,'11':10,'12':11,\n",
    "       '13':12,'14':13,'15':14,'16':15,'17':16,'18':17,'19':18,'20':19,'21':20,'22':21,\n",
    "       '23':22,'24':23,'25':24}\n",
    "folder_to_save_results='results_test/'\n",
    "\n",
    "#Check if the directory exists. If not, then create the directory.\n",
    "if not os.path.exists(folder_to_save_results):\n",
    "    os.makedirs(folder_to_save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zones_under_analysis\n",
    "# analysis_zones=['WA_SEATAC','WA_W','OR_W','CA_PGE_N','CA_PGE_BAY','CA_PGE_CEN',\n",
    "#                 'CA_PGE_S','CA_SCE_CEN','CA_LADWP','CA_SCE_S','CA_SDGE','MEX_BAJA'] #these are coastal load zones\n",
    "analysis_period=[2050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shape file\n",
    "wecc_load_areas = gpd.read_file('shape_files/wecc_load_areas.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/switch/wave_cases_v2/s1/outputs/dispatch.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/nataliagonzalez/switch/notebooks_wave/utils.py\", line 32, in get_single_df\n    pd.read_csv(fname, *args, **kwargs)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n    return func(*args, **kwargs)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 575, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 934, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1218, in _make_engine\n    self.handles = get_handle(  # type: ignore[call-overload]\n  File \"/Users/nataliagonzalez/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\", line 786, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/data/switch/wave_cases_v2/s1/outputs/dispatch.csv'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2a7c14357b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dispatch.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdispatch\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"scenario\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshort_names\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/switch/notebooks_wave/utils.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(scenario, fname, fpath, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         fname_dfs = Parallel(n_jobs=-1)(\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_single_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msce\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/switch/wave_cases_v2/s1/outputs/dispatch.csv'"
     ]
    }
   ],
   "source": [
    "# Load the csv file from specified scenarios\n",
    "fname = \"dispatch.csv\"\n",
    "\n",
    "dispatch = get_data(scenario, fname)\n",
    "dispatch  = dispatch .replace({\"scenario\": short_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shape file\n",
    "wecc_load_areas = gpd.read_file('shape_files/wecc_load_areas.shp')\n",
    "\n",
    "# Load the csv file\n",
    "dispatch = pd.read_csv('dispatch.csv')\n",
    "\n",
    "# Merge the shape file with the csv file based on the load zone\n",
    "wecc_load_areas_dispatch = wecc_load_areas.merge(dispatch, on='load_zone')\n",
    "\n",
    "# Group the data by load zone and calculate the sum of offshore wind and wave energy\n",
    "grouped_dispatch = wecc_load_areas_dispatch.groupby('load_zone').sum()[['offshore_wind_energy', 'wave_energy']]\n",
    "\n",
    "# Plot a pie chart for each load zone\n",
    "for i, row in wecc_load_areas_dispatch.iterrows():\n",
    "    # Calculate the size of the pie chart based on the total amount of offshore wind and wave energy dispatched\n",
    "    size = (row['offshore_wind_energy'] + row['wave_energy']) / grouped_dispatch.loc[row['load_zone']].sum()\n",
    "    # Create the pie chart\n",
    "    plt.pie([row['offshore_wind_energy'], row['wave_energy']], radius=size, labels=['Offshore Wind Energy', 'Wave Energy'], autopct='%1.1f%%')\n",
    "    # Set the title of the pie chart to the load zone\n",
    "    plt.title(row['load_zone'])\n",
    "    # Save the pie chart as an image file\n",
    "    plt.savefig(f'{row[\"load_zone\"]}.png')\n",
    "    # Close the figure\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
